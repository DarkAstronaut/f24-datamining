{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "MCIS6273 Data Mining (Prof. Maull) / Fall 2024 / HW0\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 20 | Friday October 4 @ Midnight | _up to_ 18 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Familiarize yourself with Github and basic git\n", "\n", "* Familiarize yourself with the JupyterLab environment, Markdown and Python\n", "\n", "* Explore JupyterHub Linux console integrating what you learned in the prior parts of this homework\n", "\n", "* Perform basic data engineering in Python using Crossref Metadata\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw0`.   Put all of your files in that directory.  Then zip or tar that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw0_files.zip`, `maull_hw0_files.tar.gz`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (0%) Familiarize yourself with Github and basic git \n", "\n", "[Github (https://github.com)](https://github.com) is the _de facto_ platform for open source software in the world based\n", "on the very popular [git (https://git-scm.org)](https://git-scm.org) version control system. Git has a sophisticated set\n", "of tools for version control based on the concept of local repositories for fast commits and remote\n", "repositories only when collaboration and remote synchronization is necessary.  Github enhances git by providing\n", "tools and online hosting of public and private repositories to encourage and promote sharing and collaboration.\n", "Github hosts some of the world's most widely used open source software.\n", "\n", "**If you are already familiar with git and Github, then this part will be very easy!**\n", "\n", "**&#167; Task:**  **Create a Zotero account.**\n", "\n", "Learn about Zotero and if you haven't already, create a free account:\n", "\n", "* [https://zotero.org](https://zotero.org)\n", "\n", "\n", "**&#167; Task:**  **Create a public Github repo named `\"mcis6273-f24-datamining\"` and place a `README.md` file in it.**\n", "\n", "Create your first file called\n", "`README.md` at the top level of the repository.  \n", "\n", "Please put your Zotero username in the file. Aside from that you can put whatever text you like in the file \n", "(If you like, use something like [lorem ipsum](https://lipsum.com/)\n", "to generate random sentences to place in the file.).\n", "Please include the link to **your** Github repository that now includes the minimal `README.md`. \n", "You don't have to have anything elaborate in that file or the repo. \n", "\n", "\n", "**&#167; Task:**  **Fork the course repository.**\n", "\n", "Learn to use Github workflows and fork the class repo:\n", "\n", "* [https://github.com/kmsaumcis/mcis6273_f24_datamining/](https://github.com/kmsaumcis/mcis6273_f24_datamining/)\n", "\n", "\n", "\n", "### (0%) Familiarize yourself with the JupyterLab environment, Markdown and Python \n", "\n", "As stated in the course announcement [Jupyter (https://jupyter.org)](https://jupyter.org) is the\n", "core platform we will be using in this course and\n", "is a popular platform for data scientists around the world.  We have a JupyterLab\n", "setup for this course so that we can operate in a cloud-hosted environment, free from\n", "some of the resource constraints of running Jupyter on your local machine (though you are free to set\n", "it up on your own and seek my advice if you desire).\n", "\n", "You have been given the information about the  Jupyter environment we have setup for our course, and\n", "the underlying Python environment will be using is the [Anaconda (https://anaconda.com)](https://anaconda.com)\n", "distribution.  It is not necessary for this assignment, but you are free to look at the multitude\n", "of packages installed with Anaconda, though we will not use the majority of them explicitly.\n", "\n", "As you will soon find out, Notebooks are an incredibly effective way to mix code with narrative\n", "and you can create cells that are entirely code or entirely Markdown.  Markdown (MD or `md`) is\n", "a highly readable text format that allows for easy documentation of text files, while allowing\n", "for HTML-based rendering of the text in a way that is style-independent.\n", "\n", "We will be using Markdown frequently in this course, and you will learn that there are many different\n", "\"flavors\" or Markdown.  We will only be using the basic flavor, but you will benefit from exploring\n", "the \"Github flavored\" Markdown, though you will not be responsible for using it in this course -- only the\n", "\"basic\" flavor.  Please refer to the original course announcement about Markdown.\n", "\n", "**&#167; Task:**  **THERE IS NOTHING TO TURN IN FOR THIS PART.** \n", "\n", "Play with and become familiar with the basic functions of\n", "the Lab environment given to you online in the course Blackboard.\n", "\n", "\n", "**&#167; Task:**  **THERE IS NOTHING TO TURN IN FOR THIS PART.** \n", "\n", "Please _create a markdown document_ and\n", "read the documentation for basic Markdown [here](https://www.markdownguide.org/basic-syntax). \n", "Learn to use all of the following:\n", "\n", "* headings (one level is fine),\n", "* bullets,\n", "* bold and italics\n", "\n", "Again, the content of your documentcan be whatever you like, just learn some\n", "of the basic functionality of Markdown.  \n", "\n", "\n", "\n", "### (0%) Explore JupyterHub Linux console integrating what you learned in the prior parts of this homework \n", "\n", "The Linux console in JupyterLab is a great way to perform command-line tasks and is an essential tool\n", "for basic scripting that is part of a data scientist's toolkit.  Open a console in the lab environment\n", "and familiarize yourself with your files and basic commands using git as indicated below.\n", "\n", "1. In a new JupyterLab command line console, run the `git clone` command to clone the new\n", "  repository you created in the prior part.\n", "  You will want to read the documentation on this \n", "  command (try here [https://www.git-scm.com/docs/git-clone](https://www.git-scm.com/docs/git-clone) to get a good\n", "  start).\n", "2. Within the same console, modify your `README.md` file, check it in and push it back to your repository, using\n", "  `git push`.  Read the [documentation about `git push`](https://git-scm.com/docs/git-push).\n", "3. The commands `wget` and `curl` are useful for grabbing data and files from remote resources off the web.\n", "  Read the documentation on each of these commands by typing `man wget` or `man curl` in the terminal.\n", "  Make sure you pipe the output to a file or use the proper flags to do so.\n", "\n", "**&#167; Task:**  **THERE IS NOTHING TO TURN IN FOR THIS PART.**\n", "\n", "\n", "\n", "### (100%) Perform basic data engineering in Python using Crossref Metadata \n", "\n", "We have learned that data engineering is an\n", "important task and ultimately the _initial_\n", "process which most data mining begins.\n", "\n", "In this assignment you will get you hands\n", "**really** dirty with _real_ data with \n", "a serious and practical application.\n", "\n", "As you may know, most published research in journals\n", "are assigned what are called DOIs or _Digital Object\n", "Identifiers_ (see: [@doi.org: What is a DOI?](https://www.doi.org/the-identifier/what-is-a-doi/)).  \n", "These DOIs are persistent, resolvable\n", "identifiers that act as a kind of \"unique ID\" for \n", "the publication.  Once assigned, they are not \n", "ever going to change, and they will also always\n", "_resolve_ to something via the HTTP/S protocol.\n", "\n", "For example, if you go to the URL: [https://doi.org/10.1109/ISSE54508.2022.10005441](https://doi.org/10.1109/ISSE54508.2022.10005441)\n", "you will end up on the landing page for the journal article for\n", "the following paper:\n", "\n", "> P. Petersen et al., \"Towards a Data Engineering Process in Data-Driven\n", "  Systems Engineering,\" 2022 IEEE International Symposium on Systems\n", "  Engineering (ISSE), Vienna, Austria, 2022, pp. 1-8, \n", "  doi: 10.1109/ISSE54508.2022.10005441.\n", "  \n", "\n", "One organization which facilitates, manages and stores\n", "metadata for all of these DOIs is [crossref.org](https://crossref.org)\n", "and they have open APIs, among other tools to access\n", "this metadata.\n", "\n", "_Data engineering_ as you have learned from the readings\n", "is about transforming data from one form to another so\n", "that it can be used in the appropriate analysis \n", "contexts.\n", "\n", "In this part of the homework you will prepare data for \n", "analysis.  You will have in front of you a dataset\n", "with nearly 1M (million) records.  The dataset\n", "is in a CSV file and it is far from perfect, not\n", "the least of which is that much of what we **want**\n", "is not quite in usable form, as you will see.\n", "\n", "Your code must be implemented in Jupyter as a notebook -- you\n", "will be required to turn in a `.ipynb` file.\n", "\n", "**&#167; Task:**  **Use Python/Pandas to load, clean and store a CSV file.**\n", "  \n", "A lot of times we would like to clean up data in \n", "a file.  In this case, we have a lot of it, and the\n", "reality is that we only need _some_ of the data\n", "in the file.\n", "\n", "You will first need to grab the `.zip`\n", "into your Jupyter environment.  Please\n", "get the file from here:\n", "\n", "* [https://github.com/kmsaumcis/mcis6273_f24_datamining/hw0/hw_data](https://github.com/kmsaumcis/mcis6273_f24_datamining/hw0/hw_data)\n", "\n", "You will then need to unzip the file on the filesystem.\n", "\n", "To unzip, open a Jupyter terminal and type:\n", "\n", "```bash\n", "  unzip -o hw0_dataset_1M.csv.zip -d data/\n", "```\n", "\n", "You will now see a file `hw0_dataset_1M.csv` in the `data/` folder.\n", "This is the CSV file you will need to use for\n", "the assignment.\n", "\n", "The final thing you will need to do is \n", "load the CSV into a DataFrame.  I am\n", "providing the loading code to\n", "get you started, so from this point, \n", "you are on your own ...\n", "\n", "To load the dataset into a DataFrame,\n", "use the following code:\n", "\n", "```python\n", "  df = pd.read_csv( \"./data/hw0_dataset_1M.csv\", names = [i for i in range(0,30)])\n", "```\n", "There is a starter notebook on Github with the first cells\n", "running these steps for you.  See:\n", "\n", "* [https://github.com/kmsaumcis/mcis6273_f24_datamining/hw0/hw0_starter_nb.ipynb](https://github.com/kmsaumcis/mcis6273_f24_datamining/hw0/hw0_starter_nb.ipynb)\n", "\n", "When you inspect the  DataFrame \n", "you will notice that the header/column names are numbers, then\n", "later you will notice that there are a larger\n", "problems, like there are rows which \n", "are not data, etc.\n", "\n", "You will need to continue cleaning this file\n", "using Pandas: [https://pandas.pydata.org](https://pandas.pydata.org).  \n", "\n", " \n", "**MINIMUM EXPECTATIONS IN THE ANSWER FOR THIS TASK PART**\n", "\n", "Your answer must include:\n", "\n", "* the cleaned files need to go into a `'data/'` folder (created by you)\n", "* the first row of your newly exported CSV file must include ALL the headers of ALL columns\n", "* all the data rows should have data and nothing else (e.g. \n", "  there should be no rows with headers or junk data, etc.)\n", "* your new cleaned output file should be called `'data/cleaned_data.csv'`\n", "\n", "**HINTS**: \n", "\n", "* to find all the header columns, you can search the DataFrame for \n", "  all rows for which the second column contains the work `'key'`. \n", "  These are the header columns and the longest will be your new\n", "  header for the DataFrame.  You will find the `DataFrame.str`\n", "  functionality very useful: see [https://pandas.pydata.org/docs/user_guide/text.html#string-methods](https://pandas.pydata.org/docs/user_guide/text.html#string-methods).\n", "* I gave the code to load data into 30 columns, you will not need them all\n", "  so when you have found the actually full column listing, remove the extraneous \n", "  columns.\n", "\n", "\n", "**&#167; Task:**  **Extract, transform and export JSON data.**\n", "\n", "Now that you have a CSV file, we will transform and deploy it\n", "to CSV and now JSON. The file needs to have the following \n", "characteristics:\n", "\n", "* the columns will be restricted to 3 columns, `DOI`, `journal-title` and `doi-asserted-by`\n", "* the `DOI` column must be normalized -- that is it must be completely lowercased\n", "* the `journal-title` column must be normalized in the following way\n", "  * remove all extraneous space in between all words, so \n", "    for example `'  tran    ieee spectrum '` becomes\n", "    `'tran ieee spectrum'`.  You may need to study [String methods](https://pandas.pydata.org/docs/user_guide/text.html#string-methods) \n", "    and\n", "    [lambda expressions](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions). \n", "  * remove all punctuation from the string, again such that a `journal-title`\n", "    like `'proc. am. math soc.'` is normalized to `'proc am math soc'`\n", "* store the finalized data set in two files (use `Pandas.to_csv()` and `Pandas.to_json()`):\n", "  * a CSV file `'data/data_cleaned_normalized.csv'`\n", "  * a JSON file `'data/data_cleaned_normalized.json'`\n", "\n", "\n", "**&#167; Task:**  **Filter, transform and export CSV data.**\n", "\n", "You will now loop over all the data to produce a filtered\n", "file  with just the unique DOIs.  You will need to\n", "\n", "* reduce the data to only those rows with a `DOI` **and** `journal-title` \n", "* you must store the data table in CSV and JSON files called `'data/data_filtered.csv'` \n", "  and `'data/data_filtered.json'` in the `'data/'` folder \n", "\n", "\n", "**&#167; Task:**  **Write functions to get journal information.**\n", "\n", "You will need to write three functions:\n", "\n", "  - one called `n_most_frequent_doi(df, n)` which takes a DataFrame and _n_ as parameters and returns the _n_ most frequent `DOIs` in a DataFrame\n", "  - one called `journal_lookup(df, s)` which takes a DataFrame and string (substring)\n", "    as parameters and returns the DataFrame which contains only those data rows\n", "    where `s` as a substring in `journal-title`.  You may need to study\n", "    [`DataFrame.str.contains()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains) as a starting point.\n", "  \n", "You will need these for the online assessment!  Do your best.\n", "\n", "\n", "**&#167; Task:**  **Complete the online HW0 assessment.**\n", "\n", "Once you are done with the coding part of the assignment, you will need to complete the online assessment for\n", "the final 6 points of your grade.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}